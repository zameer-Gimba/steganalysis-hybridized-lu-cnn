# Hybrid LU Activation Function in CNN for Steganalysis

## Overview
This project explores a **dynamic hybridization of LU-based activation functions**
(ELU, ReLU, and LeakyReLU) within a Convolutional Neural Network (CNN) architecture
for **steganalysis**.

The work was developed during my **SIWES (Industrial Training)** at  
**NITDA ICT Hub, Federal University Kashere (FUK), Gombe State**,  
under the supervision of academic and technical staff.

The motivation is to improve feature sensitivity in steganalysis tasks, where
hidden information introduces subtle statistical deviations in image data.


## Key Idea
Instead of using a fixed activation function throughout the CNN, this approach:

- Observes activation output behavior
- Dynamically selects ELU, ReLU, or LeakyReLU
- Iteratively refines the modelâ€™s non-linearity

This hybrid strategy aims to enhance representational robustness for detecting
steganographic patterns.


## How to Run
1. Install Dependencies
```bash
pip install -r requirements.txt
```
2. Run the Model
```
python src/hybrid_lu_cnn.py
```
3. Run Tests
```
python src/hybrid_lu_cnn.py
```
## Results

Experimental visualizations such as activation distributions and architecture
comparisons are stored in the results/ directory.

Note: Results are dataset-dependent and can be regenerated by extending the
current model with real steganalysis datasets.

## Academic Context

This project is part of my Machine Learning internship experience and is
included in my CV as applied research work in deep learning for information
security.

## License

This project is intended for educational and research purposes.
